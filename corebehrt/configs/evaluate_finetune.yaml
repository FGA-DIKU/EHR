env: local

paths:
  model_path: "./outputs/finetuning"
  test_data_dir: "./outputs/held_out/processed_data" 
  run_name: "evaluate"

  predictions: "./outputs/evaluate/predictions"

test_batch_size: 128

metrics:
  accuracy:
    _target_: corebehrt.modules.monitoring.metrics.Accuracy
    threshold: 0.6
  balanced_accuracy:
    _target_: corebehrt.modules.monitoring.metrics.Balanced_Accuracy
  precision:
    _target_: corebehrt.modules.monitoring.metrics.Precision
  recall:
    _target_: corebehrt.modules.monitoring.metrics.Recall
  roc_auc:
    _target_: corebehrt.modules.monitoring.metrics.ROC_AUC
  pr_auc:
    _target_: corebehrt.modules.monitoring.metrics.PR_AUC

save_info: 
  sequence_length: corebehrt.main.helper.evaluate_finetune.get_sequence_length