logging:
  level: INFO
  path: ./outputs/logs

paths:
  model: "./outputs/decoder"  # Path to your trained decoder model
  test_data_dir: "./outputs/testing/held_out/processed_data_decoder"  # Path to test data
  run_name: "evaluate_decoder"
  predictions: "./outputs/testing/held_out/decoder_predictions"

# Evaluation parameters
test_batch_size: 128

# Sequence generation parameters
sequence_generation:
  max_length: 50  # Maximum length of generated sequences
  do_sample: true  # Enable sampling instead of greedy decoding
  temperature: 0.8  # Sampling temperature (lower = more focused, higher = more random)
  top_k: 50  # Top-k sampling parameter
  top_p: 0.9  # Top-p (nucleus) sampling parameter
  repetition_penalty: 1.1  # Penalty for repeating tokens

sequence_evaluation:
  outcomes: ['DE11']
  metrics: 
    roc_auc: 
      _target_: sklearn.metrics.roc_auc_score

# Save additional information
save_info: 
  sequence_length: 
    _target_: corebehrt.main.helper.evaluate_decoder.get_sequence_length 