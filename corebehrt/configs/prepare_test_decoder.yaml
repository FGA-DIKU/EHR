logging:
  level: INFO
  path: ./outputs/logs

paths:
## INPUTS
  features: ./outputs/features
  tokenized: ./outputs/tokenized
  # tokenized_file: ...
  # tokenized_pids: ...
  
  ## optional
  # cohort: ... # path to cohort directory

## OUTPUTS
  prepared_data: ./outputs/pretraining/processed_data/ # Save model/outputs to this folder
  #runs: ./outputs/pretraining # Use for generating a new model folder
  
data:
  type: "test"
  test_modes: ["held_out"] # list with name of features where test data is stored. Only used for test_data
  truncation_len: 30
  min_len: 2 # 0 by default
  add_decoder_tokens: true

outcome: # we will convert outcomes to binary based on whether at least one outcome is in the follow up window
  n_hours_censoring: -10 # censor time after index date (negative means before)
  n_hours_start_follow_up: 1 # start follow up (considering outcomes) time after index date (negative means before)
  n_hours_end_follow_up: null # end follow up (considering outcomes) time after index date (negative means before)
